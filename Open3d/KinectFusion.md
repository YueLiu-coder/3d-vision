## KinectFusion

### abstract

使用移动的深度相机和GPU，准确绘制室内任意场景地图，重建结果是稠密表面。

当前相机位姿同步更新，位姿估计考虑了已采集的所有深度信息，而不仅仅是上一帧



亮点

- 提出了TSDF这种模型表示形式，使得模型**易于更新**，且易于以表面形式展示
- 当前帧的相机位姿估计**考虑了所有的历史信息**，而不仅仅是相对上一帧进行相对位姿估计，在位姿估计精度上有所提升
- 第一个允许手持KinectFusion进行实时稠密的容积重建



### introduction

SFM（structure from motion）和MVS（multi-view stereo）可以提供精确的**相机跟踪**、**稀疏重建**结果以及**增量式的稠密表面重建结果**，但是都是实时的



SLAM（simultaneous localization and mapping）技术基于一个单目相机对动态场景进行**实时**的相机跟踪以及地图构建，这类方法主要是为了高效的相机跟踪而优化，其重建的地图是稀疏点云只能算是初步的场景重建结果



背景情况

- Kindect Sensor

  640*480分辨率，11位深度图，2^11，也就是2048mm，为2m多，采集频率为30Hz，这个设备本身会给重建任务带来一些挑战，比如深度图会含有孔洞。这可能是由于场景中某些材料不反射它发出的光，或者一些非常薄的结构使得光线切线入射，该设备存在motion blur，

- 无漂移的SLAM

- 基于深度相机的稠密跟踪建图

- 稠密场景表示

  SDF（Signed Distance Function）符号距离函数用于深度图的融合

  - 0表示表面
  - 正值表示模型外部点
  - 负值表示模型内部点
  - 数值正比于点到最近表面的距离

  表面容易提取为函数的零交叉点，给定一个SDF函数，有两种方法用于渲染出表面：

  - marching cubes算法提取联结表面
  - 表面直接进行射线投影方法

- 基于深度相机的稠密SLAM



### Method

重建的流程

![reconstruction_flow](..\Picture\reconstruction_flow.png)

1. Measurement，预处理阶段，将采集到的深度图转化为**稠密顶点图**和**法向量图**

   - 双边滤波：对采集的深度图进行去噪
   - 深度图中的**像素坐标**，通过**相机内参**和**深度值**，可以对应到相机坐标系下的三维点，再通过后续估计的相机位姿，即可对应到模型中的三维点坐标
   - **相邻像素**在相机系下的三维点坐标经过相减，叉乘即可计算出当前帧的法向量图
   - 对双边滤波的结果进行两次下采样再计算顶点图和法向量图

   

2. Pose Estimation，使用多尺度ICP对齐当前帧和已重建的模型，估计当前帧的位姿，本文基于GPU的实现考虑了所有历史信息

   - 使用所有的历史信息进行稠密的ICP姿态估计是基于两个考虑：
     - 通过保持高帧率的跟踪，可以假设**相邻帧的移动是很微小的**，因此可以通过快速投影关联法获得点对之前的关系
     - GPU支持并行处理，因此点对关联和平面优化可以使用所有历史信息，猜测大概意思是所有历史信息
   - 相比于以往的方法都是使用ICP估计**当前帧**和**上一帧**的位姿，本文估计当前帧和历史信息重建出的模型的位姿
   - 优化目标：当前帧和模型匹配点对在模型点的法向量方向上的投影距离尽可能小（**ICP目标**）
   - 使用了相邻帧移动很小的假设，建立增量变换模型，采用迭代优化的方法进行最小化目标函数

   

3. Update Reconstruction：全局场景融合，给定当前帧的位姿。将当前帧的表面信息融合进重建的模型，模型表示为**TSDF（Truncated signed distance function），截断符号距离函数**

   - 有了当前**深度帧**，以及当前帧的位姿，可以将当前深度信息融合进当前重建的TSDF模型

   - TSDF模型每个体素点存储了两个值，一个表示到最近表面的截断距离，一个表示该点的权重

     截断距离的意思是

     - 对于距离最近表面的距离大于μ，且靠近相机一侧的体素点，TSDF截断距离值记为μ
     - 对于距离最近表面的距离大于μ，且远离相机一侧的体素点，不记录截断距离值，认为其为不可见区域

   - 更新TSDF的思路

     - 对于每个体素点，根据当前帧的位姿以及相机内参，计算其在图像上对应的像素坐标
     - 根据体素坐标对应到深度图中，得到的是该体素点和相机光心连线上经过的表面的深度
     - 计算体素点到相机的距离深度，和上一步得到的表面深度做差，得到截断距离，即得到当前体素点的截断距离值
     - 当前体素点的权重，与像素射线方向和表面的夹角有关，夹角越小，说明这个平面越垂直，权重越大；权重和深度有关，深度越小，说明离得越近，权重越大

     - 上述更新思路仅考虑当前帧信息，实际上还需要和上一帧的结果进行融合，融合方式是和上一帧进行加权平均，权重就是每一帧计算出的体素权重；权重的融合方式就是相加
     - 这种更新方式虽然访问了大量无需访问的体素，但是简单并且可并行，因此总时间是较短的

   

4. Surface Prediction：对TSDF模型进行射线投影，估计出当前模型的稠密表面表示以供展示

   - 目的是计算出当前重建的TSDF模型对应的表面顶点以及法向量
     - 每个像素点根据外参内参计算射线方向，从最小深度遍历，直到经过0点，或者从负值变为正值，该点即为**表面的顶点**
     - 对于非常接近表面的点，假设这一处TSDF梯度是和表面正交的，因此**表面法向量**可以通过对TSDF求梯度获得



### Results

#### 实验设置

将Kinect放置在固定位置，观察安装在转盘上的桌面物体，采集560帧图像，约19秒，TSDF体素分辨率为256^3

#### 五种对比实验设置

1. 帧数为N，估计位姿时仅用当前帧和上一帧的信息进行估计
2. 帧数小于N，估计位姿时使用当前帧和整个模型的信息进行估计
3. 帧数为N，估计位姿使用当前帧和整个模型的信息进行估计
4. N帧数据重复用了四遍，由于第一帧和第N帧几乎相同，所以假装为转盘多转了几圈，其余设置与3相同
5. 用户手持Kinect对桌面场景进行扫描，没有明显的运动规律，其余设置与3相同





### 限制和改进方向

1. 目前系统只在体积小于7平方米的容积内重建效果较好，这种稠密的容积表达方式需要太多内存，八叉树可能是一种解决方案
2. 如果很大的扫描序列将会导致偏移，需要有效地引入自动重定位技术
3. 对于这种容积表达方式怎么进行自动化的语义分割





reference:

[论文解读：KinectFusion基于深度的实时稠密三维重建&TSDF开山之作(文字纯享版)](https://zhuanlan.zhihu.com/p/281482545)

